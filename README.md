## Incoming
- [Agentic AI](./AgenticAI/README.md)
- [Machine Learning for Beginners from Microsoft](https://github.com/microsoft/ML-For-Beginners)
- [/r/ThinkingDeeplyAI](./ThinkingDeeplyAI/README.md)
- [John Savill](https://www.youtube.com/@NTFAQGuy/featured):
    - [Agentic AI](https://www.youtube.com/watch?v=UYJ539hgDS0)
        - This source explores the concept of **agentic AI**, defining it as an autonomous AI capable of **complex planning and execution** without constant human intervention, triggered by various events.
        - It contrasts agentic AI with basic AI agents, emphasizing its ability to **dynamically create solutions** rather than following predefined workflows.
        - The discussion then transitions into practical implementation, showcasing both **low-code solutions** like Co-pilot Studio, which enable generative orchestration and custom knowledge integration, and **pro-code solutions** using Semantic Kernel, highlighting its structure for multi-agent systems and collaboration.
        - The source concludes by stressing the importance of **governance, testing, and data security** when deploying these powerful, autonomous AI agents.
    - [Azure AI Foundry Overview](https://www.youtube.com/watch?v=Sq8Cq7RZM2o)
        - The source provides an extensive overview of **Azure AI Foundry**, highlighting its role as a **comprehensive platform for professional-code AI development**.
        - It distinguishes between **Microsoft's pre-built Copilots**, user-created "little c" copilots using **Copilot Studio (low-code)**, and the advanced **pro-code capabilities of Azure AI Foundry**.
        - The discussion covers **model management**, including a vast catalog of models and tools for **evaluation and fine-tuning**, and emphasizes the importance of **content safety** and **developer tooling** such as agents and prompt flow.
        - Ultimately, the source positions **Azure AI Foundry** as the **centralized environment for integrating AI solutions** with existing enterprise infrastructure.
    - [MCP or A2A](https://www.youtube.com/watch?v=IMcDEvXRBkY)
        - The provided text explains two distinct protocols, Model Context Protocol (MCP) and Agent-to-Agent (A2A), designed to simplify interactions within AI applications and multi-agent systems.
        - MCP provides a standardized method for an AI application to communicate with various external knowledge bases and tools, abstracting away their specific communication protocols.
        - This allows large language models (LLMs) to leverage external information and capabilities easily.
        - In contrast, A2A is a JSON-based protocol enabling different AI agents to discover each other's capabilities via "agent cards" and communicate seamlessly to collaborate on tasks, supporting complex, multi-turn interactions.
        - Ultimately, the source emphasizes that both MCP and A2A serve different, complementary purposes, and both are crucial for building robust and capable AI systems.
    - [Choosing your first AI application](https://www.youtube.com/watch?v=0Ly34nFESQk)
        - The video explains how to select an initial AI application within an organization.
        - It emphasizes focusing on generative AI while acknowledging other AI types.
        - The video outlines crucial preparatory steps, including employee training, data readiness, content safety, and strong evaluation capabilities, before discussing common use cases.
        - Finally, it details key factors for choosing a first AI workload, such as tangible business value, data accessibility, technical feasibility, minimal ethical implications, and scalability, advocating for a safe, measurable, and impactful starting point that often involves human-assisted AI solutions.
    - [MCP Overview](https://www.youtube.com/watch?v=1Pf2rW5FsqQ)
        - Explains the Model Context Protocol (MCP), a new standard designed to simplify Large Language Model (LLM) integration with external services, data, and tools.
        - Historically, applications using LLMs had to manage complex APIs and describe available capabilities to the LLM, a laborious process.
        - MCP introduces a client-server architecture where MCP servers act as intermediaries, translating specific service protocols into a universal MCP format, making external resources easily discoverable and accessible to AI applications.
        - This standardization, similar to USB-C for physical devices, aims to streamline the development of generative AI applications by abstracting away the complexities of disparate systems.
    - [AI and ML](https://www.youtube.com/watch?v=C7Iu2lcoAQ4)
        - The source text offers a comprehensive introduction to Artificial Intelligence (AI) and Machine Learning (ML), defining AI as software exhibiting human-like abilities and explaining how ML enables this through algorithms that learn from data.
        - It distinguishes between rule-based AI, which is limited, and ML approaches, including supervised learning (using labeled data for prediction), unsupervised learning (finding patterns in unlabeled data), and reinforcement learning (maximizing rewards in dynamic environments).
        - The text then introduces generative AI, specifically large language models (LLMs), explaining their reliance on neural networks trained on vast datasets to predict subsequent tokens based on user prompts.
        - Finally, it differentiates between assistants (human-triggered) and agents (event-triggered autonomous systems), clarifying key concepts like multimodality, context length, and the stateless nature of these models.

## Resources
- [Lots of other exciting AI resources](Index.md)
